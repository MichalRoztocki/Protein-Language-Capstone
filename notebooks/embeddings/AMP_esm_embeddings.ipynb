{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ee1b4d-ee2f-446d-b491-690a3ec6eeab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AMP - Antimicrobial Peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c0ad7-9396-4e6a-99a2-0e3adc315f51",
   "metadata": {},
   "source": [
    "After cleaning our original csv files, we converted them to fasta format.\n",
    "\n",
    "These fasta files are input to the [script](https://github.com/facebookresearch/esm/blob/main/scripts/extract.py)  that efficiently extracts embeddings in bulk.\n",
    "\n",
    "The script `scripts/extract.py` stores embeddings in PyTorch `.pt` files (generated by `torch.save`) - one file per fasta sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ddaeab-e8d0-4cf4-82f0-806359029772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:41.756961Z",
     "iopub.status.busy": "2022-10-03T01:56:41.756596Z",
     "iopub.status.idle": "2022-10-03T01:56:41.767962Z",
     "shell.execute_reply": "2022-10-03T01:56:41.766419Z",
     "shell.execute_reply.started": "2022-10-03T01:56:41.756898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9333558-3b78-466c-adb9-edc661a23f06",
   "metadata": {},
   "source": [
    "Import file utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a575af-7a43-4ce5-816a-34a35bae92ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:41.769995Z",
     "iopub.status.busy": "2022-10-03T01:56:41.769682Z",
     "iopub.status.idle": "2022-10-03T01:56:43.738618Z",
     "shell.execute_reply": "2022-10-03T01:56:43.737277Z",
     "shell.execute_reply.started": "2022-10-03T01:56:41.769972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the script from different folder\n",
    "import sys  \n",
    "sys.path.append('../../scripts')\n",
    "\n",
    "# import file utilities as fu\n",
    "import file_utilities as fu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc980e-65fd-4a8b-b017-225546d22c3e",
   "metadata": {},
   "source": [
    "Create a path for the script `extract.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c901061e-be6c-48ec-a3bb-7414634b0f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:43.741078Z",
     "iopub.status.busy": "2022-10-03T01:56:43.739901Z",
     "iopub.status.idle": "2022-10-03T01:56:43.758836Z",
     "shell.execute_reply": "2022-10-03T01:56:43.756511Z",
     "shell.execute_reply.started": "2022-10-03T01:56:43.741021Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/damir/.cache/torch/hub/facebookresearch_esm_main/scripts/extract.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path for extract.py\n",
    "esm_scripts_path = '/home/damir/.cache/torch/hub/facebookresearch_esm_main/scripts'\n",
    "extract = os.path.join(esm_scripts_path, 'extract.py')\n",
    "extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0cb0c7-59f2-4ff1-86a0-f19d6c73093a",
   "metadata": {},
   "source": [
    "Initialize arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f26c94b-9639-4536-8930-7ad45a1b6efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:43.762709Z",
     "iopub.status.busy": "2022-10-03T01:56:43.761444Z",
     "iopub.status.idle": "2022-10-03T01:56:43.775788Z",
     "shell.execute_reply": "2022-10-03T01:56:43.773951Z",
     "shell.execute_reply.started": "2022-10-03T01:56:43.762664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define arguments for the file_paths function\n",
    "# First 4 are constant in this notebook\n",
    "ptmodel = 'esm'\n",
    "task = 'amp'\n",
    "file_base = 'all_data'\n",
    "pool = 'mean'  \n",
    "# Last 2 arguments we might be changing through the notebook\n",
    "model = 'esm1v_t33_650M_UR90S_1'\n",
    "emb_layer = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f401b0-1f8b-42a7-95b7-f87cb43b53cf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## all_data Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658dd8e-6aa4-4a27-8496-1a1ede406496",
   "metadata": {},
   "source": [
    "### ESM ESM-1v model - esm1v_t33_650M_UR90S_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb11b45-a965-4a9d-b01f-b16a3615cccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pooling Operation:  `mean`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c31b1-1d2b-495e-b123-f41c8029879d",
   "metadata": {},
   "source": [
    "Run the script `file_paths` to prepare paths. The default root data folder is *../../data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bff221-c802-4b04-ac89-3895e38091bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:43.781067Z",
     "iopub.status.busy": "2022-10-03T01:56:43.779777Z",
     "iopub.status.idle": "2022-10-03T01:56:43.792674Z",
     "shell.execute_reply": "2022-10-03T01:56:43.791373Z",
     "shell.execute_reply.started": "2022-10-03T01:56:43.781032Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ../../data/amp/all_data.fa \n",
      " ../../data/amp/esm/all_data/amp_all_esm1v_mean\n"
     ]
    }
   ],
   "source": [
    "# Prepare paths\n",
    "path_pt, _, path_fa = fu.file_paths(ptmodel, task, file_base, model, pool)\n",
    "print('', path_fa, '\\n', path_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a5ba9-99a2-4f4a-9544-553ba99adbe9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run the embedding script for: `esm - amp - all_data - esm1v - mean`.  \n",
    "The script reads the fasta file and creates `.pt` files with embeddings, one for each fasta sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54846a07-0185-49e0-a52e-d6f957325a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:56:43.796408Z",
     "iopub.status.busy": "2022-10-03T01:56:43.794460Z",
     "iopub.status.idle": "2022-10-03T01:59:37.954633Z",
     "shell.execute_reply": "2022-10-03T01:59:37.953617Z",
     "shell.execute_reply.started": "2022-10-03T01:56:43.796366Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damir/miniconda3/envs/proteins/lib/python3.9/site-packages/esm/pretrained.py:215: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Read ../../data/amp/all_data.fa with 4042 sequences\n",
      "Processing 1 of 36 batches (292 sequences)\n",
      "Processing 2 of 36 batches (250 sequences)\n",
      "Processing 3 of 36 batches (227 sequences)\n",
      "Processing 4 of 36 batches (204 sequences)\n",
      "Processing 5 of 36 batches (195 sequences)\n",
      "Processing 6 of 36 batches (178 sequences)\n",
      "Processing 7 of 36 batches (170 sequences)\n",
      "Processing 8 of 36 batches (159 sequences)\n",
      "Processing 9 of 36 batches (151 sequences)\n",
      "Processing 10 of 36 batches (146 sequences)\n",
      "Processing 11 of 36 batches (136 sequences)\n",
      "Processing 12 of 36 batches (132 sequences)\n",
      "Processing 13 of 36 batches (124 sequences)\n",
      "Processing 14 of 36 batches (120 sequences)\n",
      "Processing 15 of 36 batches (117 sequences)\n",
      "Processing 16 of 36 batches (110 sequences)\n",
      "Processing 17 of 36 batches (107 sequences)\n",
      "Processing 18 of 36 batches (104 sequences)\n",
      "Processing 19 of 36 batches (99 sequences)\n",
      "Processing 20 of 36 batches (95 sequences)\n",
      "Processing 21 of 36 batches (91 sequences)\n",
      "Processing 22 of 36 batches (87 sequences)\n",
      "Processing 23 of 36 batches (83 sequences)\n",
      "Processing 24 of 36 batches (78 sequences)\n",
      "Processing 25 of 36 batches (73 sequences)\n",
      "Processing 26 of 36 batches (69 sequences)\n",
      "Processing 27 of 36 batches (65 sequences)\n",
      "Processing 28 of 36 batches (59 sequences)\n",
      "Processing 29 of 36 batches (55 sequences)\n",
      "Processing 30 of 36 batches (52 sequences)\n",
      "Processing 31 of 36 batches (48 sequences)\n",
      "Processing 32 of 36 batches (42 sequences)\n",
      "Processing 33 of 36 batches (39 sequences)\n",
      "Processing 34 of 36 batches (33 sequences)\n",
      "Processing 35 of 36 batches (30 sequences)\n",
      "Processing 36 of 36 batches (22 sequences)\n",
      "CPU times: user 1min 32s, sys: 1min 1s, total: 2min 34s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run embedding script\n",
    "%run \"{extract}\" \"{model}\" \"{path_fa}\" \"{path_pt}\" --repr_layers \"{emb_layer}\" --include \"{pool}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b5f06-1692-49ea-872f-497652cf7b99",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ESM-1b model - esm1b_t33_650M_UR50S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8869b-bf7e-4499-a4a8-c8eafa151ad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Pooling Operation:  `mean`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5c85c-dd62-47bd-a636-4bfbecc204c5",
   "metadata": {},
   "source": [
    "Update arguments and prepare paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f40db39-cbaa-4121-88e9-13a4d11d1c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:59:37.957678Z",
     "iopub.status.busy": "2022-10-03T01:59:37.957389Z",
     "iopub.status.idle": "2022-10-03T01:59:37.970243Z",
     "shell.execute_reply": "2022-10-03T01:59:37.969008Z",
     "shell.execute_reply.started": "2022-10-03T01:59:37.957657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ../../data/amp/all_data.fa \n",
      " ../../data/amp/esm/all_data/amp_all_esm1b_mean\n"
     ]
    }
   ],
   "source": [
    "# Update arguments\n",
    "model = 'esm1b_t33_650M_UR50S'\n",
    "emb_layer = 33\n",
    "# Prepare paths\n",
    "path_pt, _, path_fa = fu.file_paths(ptmodel, task, file_base, model, pool)\n",
    "print('', path_fa, '\\n', path_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4847d6-68b4-47c7-9e5f-079db105ffa2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run the embedding script for: `esm - amp - all_data - esm1b - mean`.  \n",
    "The script reads the fasta file and creates `.pt` files with embeddings, one for each fasta sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eab555e-1f94-4595-9c76-8eb481f9a3bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T01:59:37.973168Z",
     "iopub.status.busy": "2022-10-03T01:59:37.972145Z",
     "iopub.status.idle": "2022-10-03T02:01:49.483195Z",
     "shell.execute_reply": "2022-10-03T02:01:49.471217Z",
     "shell.execute_reply.started": "2022-10-03T01:59:37.973134Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred model to GPU\n",
      "Read ../../data/amp/all_data.fa with 4042 sequences\n",
      "Processing 1 of 36 batches (292 sequences)\n",
      "Processing 2 of 36 batches (250 sequences)\n",
      "Processing 3 of 36 batches (227 sequences)\n",
      "Processing 4 of 36 batches (204 sequences)\n",
      "Processing 5 of 36 batches (195 sequences)\n",
      "Processing 6 of 36 batches (178 sequences)\n",
      "Processing 7 of 36 batches (170 sequences)\n",
      "Processing 8 of 36 batches (159 sequences)\n",
      "Processing 9 of 36 batches (151 sequences)\n",
      "Processing 10 of 36 batches (146 sequences)\n",
      "Processing 11 of 36 batches (136 sequences)\n",
      "Processing 12 of 36 batches (132 sequences)\n",
      "Processing 13 of 36 batches (124 sequences)\n",
      "Processing 14 of 36 batches (120 sequences)\n",
      "Processing 15 of 36 batches (117 sequences)\n",
      "Processing 16 of 36 batches (110 sequences)\n",
      "Processing 17 of 36 batches (107 sequences)\n",
      "Processing 18 of 36 batches (104 sequences)\n",
      "Processing 19 of 36 batches (99 sequences)\n",
      "Processing 20 of 36 batches (95 sequences)\n",
      "Processing 21 of 36 batches (91 sequences)\n",
      "Processing 22 of 36 batches (87 sequences)\n",
      "Processing 23 of 36 batches (83 sequences)\n",
      "Processing 24 of 36 batches (78 sequences)\n",
      "Processing 25 of 36 batches (73 sequences)\n",
      "Processing 26 of 36 batches (69 sequences)\n",
      "Processing 27 of 36 batches (65 sequences)\n",
      "Processing 28 of 36 batches (59 sequences)\n",
      "Processing 29 of 36 batches (55 sequences)\n",
      "Processing 30 of 36 batches (52 sequences)\n",
      "Processing 31 of 36 batches (48 sequences)\n",
      "Processing 32 of 36 batches (42 sequences)\n",
      "Processing 33 of 36 batches (39 sequences)\n",
      "Processing 34 of 36 batches (33 sequences)\n",
      "Processing 35 of 36 batches (30 sequences)\n",
      "Processing 36 of 36 batches (22 sequences)\n",
      "CPU times: user 1min 36s, sys: 23.1 s, total: 1min 59s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run embedding script\n",
    "%run \"{extract}\" \"{model}\" \"{path_fa}\" \"{path_pt}\" --repr_layers \"{emb_layer}\" --include \"{pool}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0596c-0cad-4213-a467-3c198ead63bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Check the folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f7fd0c-0616-4785-a8e9-23c3cdc99c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T02:01:49.510767Z",
     "iopub.status.busy": "2022-10-03T02:01:49.508798Z",
     "iopub.status.idle": "2022-10-03T02:01:50.807842Z",
     "shell.execute_reply": "2022-10-03T02:01:50.806592Z",
     "shell.execute_reply.started": "2022-10-03T02:01:49.510402Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/amp/esm/all_data\n",
      "├── [4.0K Oct  2 22:01]  amp_all_esm1b_mean\n",
      "└── [4.0K Oct  2 21:59]  amp_all_esm1v_mean\n",
      "\n",
      "2 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "base = os.path.split(path_pt)[0]\n",
    "!tree -nDhL 1 \"{base}\" --dirsfirst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711a7c3-96bf-411e-af07-021b951b5d5b",
   "metadata": {},
   "source": [
    "Print the total size and number of pt files in each embedding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16afce4-ddf5-4f6e-a808-dc39cd3b30f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T02:01:50.811113Z",
     "iopub.status.busy": "2022-10-03T02:01:50.810610Z",
     "iopub.status.idle": "2022-10-03T02:02:13.404371Z",
     "shell.execute_reply": "2022-10-03T02:02:13.403191Z",
     "shell.execute_reply.started": "2022-10-03T02:01:50.811079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp_all_esm1b_mean consumes: 22.86MB in 4042 files\n",
      "amp_all_esm1v_mean consumes: 22.86MB in 4042 files\n"
     ]
    }
   ],
   "source": [
    "# Print the total size and number of pt files in each embedding folder\n",
    "fu.emb_files_stats(path_pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteins",
   "language": "python",
   "name": "conda-env-proteins-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
